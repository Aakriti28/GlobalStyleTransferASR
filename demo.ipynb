{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aakri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\aakri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\.libs\\libopenblas.JPIJNSWNNAN3CE6LLI5FWSPHUT2VXMTH.gfortran-win_amd64.dll\n",
      "c:\\users\\aakri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "c:\\users\\aakri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "from onmt_modules.misc import sequence_mask\n",
    "# from model_autopst import Generator_2 as Predictor\n",
    "from hparams_autopst import hparams\n",
    "from utils import filter_bank_mean\n",
    "from fast_decoders import DecodeFunc_Sp\n",
    "from model_sea import Encoder_2 as Encoder_Code_2\n",
    "from override_decoder import OnmtDecoder_1 as OnmtDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onmt_modules.misc import sequence_mask\n",
    "from onmt_modules.embeddings import PositionalEncoding\n",
    "from onmt_modules.encoder_transformer import TransformerEncoder as OnmtEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prenet(nn.Module):\n",
    "    def __init__(self, dim_input, dim_output, dropout=0.1):\n",
    "        super().__init__() \n",
    "        \n",
    "        mlp = nn.Linear(dim_input, dim_output, bias=True)\n",
    "        pe = PositionalEncoding(dropout, dim_output, 1600)\n",
    "        \n",
    "        self.make_prenet = nn.Sequential()\n",
    "        self.make_prenet.add_module('mlp', mlp)\n",
    "        self.make_prenet.add_module('pe', pe)\n",
    "        \n",
    "        self.word_padding_idx = 1\n",
    "        \n",
    "    def forward(self, source, step=None):\n",
    "        \n",
    "        for i, module in enumerate(self.make_prenet._modules.values()):\n",
    "            if i == len(self.make_prenet._modules.values()) - 1:\n",
    "                source = module(source, step=step)\n",
    "            else:\n",
    "                source = module(source)\n",
    "                \n",
    "        return source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Tx_Spk(nn.Module):\n",
    "    \"\"\"\n",
    "    Text Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__() \n",
    "        \n",
    "        prenet = Prenet(hparams.dim_code+hparams.dim_spk, \n",
    "                        hparams.enc_rnn_size)\n",
    "        self.encoder = OnmtEncoder.from_opt(hparams, prenet)\n",
    "        \n",
    "    def forward(self, src, src_lengths, spk_emb):\n",
    "        \n",
    "        spk_emb = spk_emb.unsqueeze(0).expand(src.size(0),-1,-1)\n",
    "        src_spk = torch.cat((src, spk_emb), dim=-1)\n",
    "        enc_states, memory_bank, src_lengths = self.encoder(src_spk, src_lengths)\n",
    "        \n",
    "        return enc_states, memory_bank, src_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_Sp(nn.Module):\n",
    "    \"\"\"\n",
    "    Speech Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.dim_freq = hparams.dim_freq\n",
    "        self.max_decoder_steps = hparams.dec_steps_sp\n",
    "        self.gate_threshold = hparams.gate_threshold\n",
    "        \n",
    "        prenet = Prenet(hparams.dim_freq, hparams.dec_rnn_size)\n",
    "        self.decoder = OnmtDecoder.from_opt(hparams, prenet)\n",
    "\n",
    "        self.postnet = nn.Linear(hparams.dec_rnn_size, \n",
    "                                 hparams.dim_freq+1, bias=True)\n",
    "        \n",
    "    def forward(self, tgt, tgt_lengths, memory_bank, memory_lengths):\n",
    "        \n",
    "        dec_outs, attns = self.decoder(tgt, memory_bank, step=None, \n",
    "                                       memory_lengths=memory_lengths,\n",
    "                                       tgt_lengths=tgt_lengths)\n",
    "        spect_gate = self.postnet(dec_outs)\n",
    "        spect, gate = spect_gate[:, :, 1:], spect_gate[:, :, :1]\n",
    "        \n",
    "        return spect, gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    '''\n",
    "    async stage 2\n",
    "    '''\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.encoder_cd = Encoder_Code_2(hparams)\n",
    "        self.encoder_tx = Encoder_Tx_Spk(hparams)\n",
    "        self.decoder_sp = Decoder_Sp(hparams)   \n",
    "        self.encoder_spk = nn.Linear(hparams.dim_spk, \n",
    "                                     hparams.enc_rnn_size, bias=True)\n",
    "        self.fast_dec_sp = DecodeFunc_Sp(hparams, 'Sp')\n",
    "        \n",
    "        \n",
    "    def forward(self, cep_in, mask_long, codes_mask, num_rep, len_short,\n",
    "                      tgt_spect, len_spect, \n",
    "                      spk_emb):\n",
    "        \n",
    "        cd_long = self.encoder_cd(cep_in, mask_long)\n",
    "        fb = filter_bank_mean(num_rep, codes_mask, cd_long.size(1))\n",
    "        \n",
    "        cd_short = torch.bmm(fb.detach(), cd_long.detach())\n",
    "        \n",
    "        spk_emb_1 = self.encoder_spk(spk_emb)\n",
    "        \n",
    "        # text to speech\n",
    "        _, memory_tx, _ = self.encoder_tx(cd_short.transpose(1,0), len_short, \n",
    "                                          spk_emb)\n",
    "        memory_tx_spk = torch.cat((spk_emb_1.unsqueeze(0), memory_tx), dim=0)\n",
    "        self.decoder_sp.decoder.init_state(memory_tx_spk, None, None)\n",
    "        spect_out, gate_sp_out \\\n",
    "        = self.decoder_sp(tgt_spect, len_spect, memory_tx_spk, len_short+1)\n",
    "        \n",
    "        return spect_out, gate_sp_out\n",
    "    \n",
    "    \n",
    "    def infer_onmt(self, cep_in, mask_long, len_spect,\n",
    "                   spk_emb):\n",
    "        \n",
    "        cd_long = self.encoder_cd(cep_in, mask_long)\n",
    "        \n",
    "        spk_emb_1 = self.encoder_spk(spk_emb)\n",
    "        \n",
    "        # text to speech\n",
    "        _, memory_tx, _ = self.encoder_tx(cd_long.transpose(1,0), len_spect, \n",
    "                                          spk_emb)\n",
    "        memory_tx_spk = torch.cat((spk_emb_1.unsqueeze(0), memory_tx), dim=0)\n",
    "        self.decoder_sp.decoder.init_state(memory_tx_spk, None, None)\n",
    "        spect_output, len_spect_out, stop_sp_output \\\n",
    "        = self.fast_dec_sp.infer(None, memory_tx_spk, len_spect+1, \n",
    "                                 self.decoder_sp.decoder, \n",
    "                                 self.decoder_sp.postnet)\n",
    "        \n",
    "        return spect_output, len_spect_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded predictor .....................................................\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "P = Predictor(hparams).eval().to(device)\n",
    "\n",
    "checkpoint = torch.load('./assets/580000-P.ckpt', map_location=lambda storage, loc: storage)  \n",
    "P.load_state_dict(checkpoint['model'], strict=True)\n",
    "print('Loaded predictor .....................................................')\n",
    "\n",
    "dict_test = pickle.load(open('./assets/test_vctk.meta', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "OrderedDict([('001', (array([[ 0.12554671, -0.16963401, -0.58115584, ..., -0.51349175,\n",
      "         1.2145282 , -0.39891607],\n",
      "       [ 0.6724523 , -0.20496637, -0.6058039 , ..., -0.01747223,\n",
      "         1.2504997 , -0.6045832 ],\n",
      "       [ 0.48696825, -0.3501245 , -0.67875063, ...,  0.22466417,\n",
      "         1.037844  , -0.31743672],\n",
      "       ...,\n",
      "       [ 0.0410398 ,  0.11647096, -0.502512  , ...,  0.35522646,\n",
      "         1.1331956 ,  1.1371542 ],\n",
      "       [-0.47664598,  0.08350065, -0.511562  , ..., -0.29939383,\n",
      "         0.00328085,  0.9134802 ],\n",
      "       [-1.1690527 ,  0.08582662, -0.736655  , ..., -0.31217238,\n",
      "         0.54107565,  0.69253266]], dtype=float32), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32))), ('003001', (array([[-1.9095297 , -1.6434065 ,  1.3263586 , ...,  0.12786523,\n",
      "        -0.31431645, -0.320904  ],\n",
      "       [-1.0554965 , -2.2249188 ,  1.162187  , ...,  0.47870415,\n",
      "         0.12550773,  0.7243602 ],\n",
      "       [-0.61171913, -2.5307288 ,  1.079268  , ..., -0.80115926,\n",
      "        -1.9930944 , -0.8266467 ],\n",
      "       ...,\n",
      "       [-0.07927172, -1.03913   ,  1.5984597 , ...,  0.6606208 ,\n",
      "         0.15988742, -0.32111943],\n",
      "       [-1.33647   , -0.2733799 ,  0.99253654, ..., -0.4455242 ,\n",
      "         0.777118  , -0.29659483],\n",
      "       [-2.5955052 , -0.68862015,  0.3773527 , ...,  0.3357537 ,\n",
      "         0.8574181 ,  0.99831593]], dtype=float32), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)))])\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_test['p231']))\n",
    "\n",
    "print(dict_test['p231'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spect_vc = OrderedDict()\n",
    "\n",
    "uttrs = [('p231', 'p270', '001'),\n",
    "         ('p270', 'p231', '001'),\n",
    "         ('p231', 'p245', '003001'),\n",
    "         ('p245', 'p231', '003001'),\n",
    "         ('p239', 'p270', '024002'),\n",
    "         ('p270', 'p239', '024002')]\n",
    "\n",
    "\n",
    "for uttr in uttrs:\n",
    "        \n",
    "    cep_real, spk_emb = dict_test[uttr[0]][uttr[2]]\n",
    "    cep_real_A = torch.from_numpy(cep_real).unsqueeze(0).to(device)\n",
    "    len_real_A = torch.tensor(cep_real_A.size(1)).unsqueeze(0).to(device)\n",
    "    real_mask_A = sequence_mask(len_real_A, cep_real_A.size(1)).float()\n",
    "    \n",
    "    _, spk_emb = dict_test[uttr[1]][uttr[2]]\n",
    "    spk_emb_B = torch.from_numpy(spk_emb).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        spect_output, len_spect = P.infer_onmt(cep_real_A.transpose(2,1)[:,:14,:],\n",
    "                                               real_mask_A,\n",
    "                                               len_real_A,\n",
    "                                               spk_emb_B)\n",
    "    \n",
    "    uttr_tgt = spect_output[:len_spect[0],0,:].cpu().numpy()\n",
    "        \n",
    "    spect_vc[f'{uttr[0]}_{uttr[1]}_{uttr[2]}'] = uttr_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                | 3/18944 [00:00<14:27, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p231_p270_001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████         | 16716/18944 [12:02<01:41, 21.86it/s]"
     ]
    }
   ],
   "source": [
    "# spectrogram to waveform\n",
    "# Feel free to use other vocoders\n",
    "# This cell requires some preparation to work, please see the corresponding part in AutoVC\n",
    "import torch\n",
    "import librosa\n",
    "import pickle\n",
    "import os\n",
    "from synthesis import build_model\n",
    "from synthesis import wavegen\n",
    "import soundfile as sf\n",
    "\n",
    "model = build_model().to(device)\n",
    "checkpoint = torch.load(\"./assets/checkpoint_step001000000_ema.pth\")\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "outs = []\n",
    "\n",
    "for name, sp in spect_vc.items():\n",
    "    print(name)\n",
    "    \n",
    "    waveform = wavegen(model, c=sp)  \n",
    "    outs.append(waveform)\n",
    "    sf.write('./assets/'+name+'.wav', waveform, 16000)\n",
    "#     write('./assets/'+name+'.wav', 16000, waveform.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
